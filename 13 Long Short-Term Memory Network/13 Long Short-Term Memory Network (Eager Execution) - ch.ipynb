{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tfe = tf.contrib.eager\n",
    "# 启动eager execution模式\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总时间步长 = 图像行数\n",
    "TIME_STEPS = 28\n",
    "# 输入维度  = 图像列数\n",
    "INPUT_SIZE = 28\n",
    "# 隐含状态单元数\n",
    "HIDDEN_SIZE = 100\n",
    "# 输出维度  = 图像类别数\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 50\n",
    "# epoches数\n",
    "NUM_EPOCH = 1\n",
    "\n",
    "# 学习率\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "       Data :\t shape: (60000, 28, 28) \t type: uint8\n",
      "       Label:\t shape: (60000,) \t\t type: uint8\n",
      "Testing set :\n",
      "       Data :\t shape: (10000, 28, 28) \t type: uint8\n",
      "       Label:\t shape: (10000,) \t\t type: uint8\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "\n",
    "print('Training set:')\n",
    "print('       Data :\\t shape:', np.shape(x_train), '\\t type:', x_train.dtype)\n",
    "print('       Label:\\t shape:', np.shape(y_train), '\\t\\t type:', y_train.dtype)\n",
    "print('Testing set :')\n",
    "print('       Data :\\t shape:', np.shape(x_test), '\\t type:', x_test.dtype)\n",
    "print('       Label:\\t shape:', np.shape(y_test), '\\t\\t type:', y_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]], shape=(60000, 10), dtype=float32) tf.Tensor(\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(10000, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 转化为 float 型并归一化\n",
    "x_train = x_train.astype(np.float32)/255\n",
    "x_test = x_test.astype(np.float32)/255\n",
    "print(np.shape(x_train), np.shape(x_test))\n",
    "\n",
    "# 标签转化为 ont hot 向量\n",
    "y_train = tf.one_hot(y_train, 10, dtype=tf.float32)\n",
    "y_test = tf.one_hot(y_test, 10, dtype=tf.float32)\n",
    "print(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. 生成Dataset对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 创建网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. 创建LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.units = hidden_size\n",
    "        \n",
    "        # 如果有GPU资源, 使用 'tf.contrib.cudnn_rnn.CudnnLSTM'\n",
    "        self.lstm = tf.nn.rnn_cell.LSTMCell(num_units = hidden_size,   # units = HIDDEN_SIZE\n",
    "                                            forget_bias=1.0,\n",
    "                                            name='basic_lstm_cell'\n",
    "                                            )\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(output_size)\n",
    "        # 如果需要输出概率，添加：\n",
    "        # self.softmax = tf.keras.layers.Softmax()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # output shape == (BATCH_SIZE, HIDDEN_SIZE) \n",
    "        outputs, final_state = tf.nn.dynamic_rnn(self.lstm, inputs,dtype=tf.float32)\n",
    "        # final_state = (c_t, h_t)\n",
    "        \n",
    "        # output shape after the dense layer == (seq_length * batch_size, vocab_size)\n",
    "        prediction = self.fc(final_state[1])\n",
    "        \n",
    "        # 如果需要输出概率，添加：\n",
    "        #     prediction = self.softmax(fc)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(y_pred, y_true):\n",
    "    '''\n",
    "    Input:\n",
    "        y_pred - [BATCH_SIZE, NUM_CLASS]\n",
    "        y      - [BATCH_SIZE, NUM_CLASS]\n",
    "    '''    \n",
    "    # 如果标签不是one-hot向量，使用sparse_softmax_cross_entropy\n",
    "    return tf.losses.softmax_cross_entropy(onehot_labels=y_true, logits=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(y_pred, y_true):\n",
    "    '''\n",
    "    Input:\n",
    "        y_pred - [BATCH_SIZE, NUM_CLASS]\n",
    "        y      - [BATCH_SIZE, NUM_CLASS]\n",
    "    '''\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_true,1), tf.argmax(y_pred,1)),tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用adam优化器，默认参数\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 - Batch     0 Loss 2.2991\n",
      "Epoch  1 - Batch   500 Loss 0.4631\n",
      "Epoch  1 - Batch  1000 Loss 0.1054\n",
      "Epoch  1 Loss 0.0913\n",
      "Time taken for 1 epoch 126.14080810546875 sec\n",
      "Test Cost:  0.1692553\n",
      "Test Accuracy:  0.9489\n"
     ]
    }
   ],
   "source": [
    "model = Model(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    start = time.time()\n",
    "    \n",
    "    # 在每个epoch开始时初始化隐藏状态，一开始为None\n",
    "    hidden = model.reset_states()\n",
    "    \n",
    "    for (batch, (x, y)) in enumerate(TrainDataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 前向传播\n",
    "            y_pred = model(x)\n",
    "            loss = Loss(y_pred, y)\n",
    "        # 反向传播\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            print ('Epoch {:2d} - Batch {:5d} Loss {:.4f}'.format(epoch+1,\n",
    "                                                          batch,\n",
    "                                                          loss))\n",
    "           \n",
    "    print ('Epoch {:2d} Loss {:.4f}'.format(epoch+1, loss))\n",
    "    print ('Time taken for 1 epoch {} sec'.format(time.time() - start))\n",
    "    \n",
    "    \n",
    "    # Testing at the end of every epoch\n",
    "    y_pred = model(x_test)\n",
    "    cost = Loss(y_pred, y_test)\n",
    "    accuracy = Accuracy(y_pred, y_test)\n",
    "    print('Test Cost: ', np.mean(cost))\n",
    "    print('Test Accuracy: ', np.mean(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
